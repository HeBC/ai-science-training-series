{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06636ce0-0b72-4ff9-95b7-aaa5dd1cb8e7",
   "metadata": {},
   "source": [
    "# Homework 04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3f83-d94e-46cf-a6e1-47a8d90fce77",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "1. **Tokenization** \n",
    "\n",
    "Write a generic Python tokenizer, which takes a set of text lines and tabulates the different words (that is, the tokens will be simply English words), keeping track of the frequency of each word.  Use the guidance in the accompanying notebook, 'Homework_1.ipynb'.\n",
    "\n",
    "2. **Embedding**\n",
    "\n",
    "Modify the embedding visualization code above to zoom in on various regions of the projections, and identify at least one interesting cluster of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fbb7d-02e8-4351-99e7-a445a958cd56",
   "metadata": {},
   "source": [
    "### 1. read words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a58d358-7775-41e2-b28d-4d9dc7645b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "wdict = {}\n",
    "total_words = 0\n",
    "with open('Life_On_The_Mississippi.txt', 'r') as L:\n",
    "    line = L.readline() \n",
    "    nlines = 1\n",
    "    while line:\n",
    "        cleaned_line = re.sub(r'[^\\x00-\\x7F]', '', line)           # eliminate any Unicode\n",
    "        line_low = cleaned_line.lower()                            # Convert to lowercase\n",
    "        trans_table = str.maketrans('', '', string.punctuation)    # remove punctuation\n",
    "        no_punctuation_text = line_low.translate(trans_table)\n",
    "        words = no_punctuation_text.split()\n",
    "        for word in words:\n",
    "            if wdict.get(word) is not None:\n",
    "                wdict[word] += 1\n",
    "            else:\n",
    "                wdict[word] = 1\n",
    "            total_words += 1\n",
    "        line = L.readline()\n",
    "        nlines += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c783d0-09c4-46db-ae7b-40653163c95c",
   "metadata": {},
   "source": [
    "### 2. sort words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44573b7d-da62-4a07-95ee-0fffb29515dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 9255)\n",
      "('and', 5892)\n",
      "('of', 4532)\n",
      "('a', 4053)\n",
      "('to', 3592)\n",
      "('in', 2593)\n",
      "('it', 2293)\n",
      "('i', 2205)\n",
      "('was', 2093)\n",
      "('that', 1724)\n",
      "('he', 1402)\n",
      "('is', 1148)\n",
      "('for', 1095)\n",
      "('with', 1081)\n",
      "('you', 1033)\n",
      "('his', 961)\n",
      "('had', 961)\n",
      "('but', 952)\n",
      "('on', 947)\n",
      "('as', 881)\n",
      "('this', 781)\n",
      "('they', 758)\n",
      "('at', 750)\n",
      "('not', 722)\n",
      "('all', 720)\n",
      "('by', 713)\n",
      "('one', 686)\n",
      "('there', 627)\n",
      "('were', 625)\n",
      "('be', 617)\n",
      "('my', 582)\n",
      "('or', 581)\n",
      "('from', 577)\n",
      "('have', 571)\n",
      "('out', 541)\n",
      "('so', 536)\n",
      "('up', 529)\n",
      "('him', 523)\n",
      "('we', 519)\n",
      "('me', 516)\n",
      "('when', 505)\n",
      "('would', 478)\n",
      "('which', 476)\n",
      "('river', 457)\n",
      "('an', 440)\n",
      "('them', 425)\n",
      "('no', 422)\n",
      "('then', 405)\n",
      "('said', 399)\n",
      "('are', 387)\n",
      "('if', 381)\n",
      "('their', 378)\n",
      "('now', 369)\n",
      "('about', 346)\n",
      "('time', 337)\n",
      "('been', 335)\n",
      "('down', 328)\n",
      "('its', 323)\n",
      "('could', 313)\n",
      "('has', 305)\n",
      "('will', 301)\n",
      "('into', 300)\n",
      "('what', 285)\n",
      "('her', 278)\n",
      "('two', 273)\n",
      "('do', 271)\n",
      "('other', 270)\n",
      "('some', 269)\n",
      "('man', 260)\n",
      "('new', 259)\n",
      "('any', 238)\n",
      "('got', 234)\n",
      "('these', 233)\n",
      "('she', 233)\n",
      "('who', 229)\n",
      "('more', 226)\n",
      "('water', 222)\n",
      "('did', 214)\n",
      "('before', 208)\n",
      "('over', 202)\n",
      "('way', 202)\n",
      "('hundred', 200)\n",
      "('upon', 200)\n",
      "('here', 199)\n",
      "('after', 195)\n",
      "('day', 193)\n",
      "('than', 192)\n",
      "('well', 191)\n",
      "('through', 191)\n",
      "('get', 190)\n",
      "('old', 186)\n",
      "('every', 186)\n",
      "('can', 185)\n",
      "('boat', 184)\n",
      "('went', 183)\n",
      "('never', 182)\n",
      "('good', 181)\n",
      "('years', 181)\n",
      "('see', 176)\n",
      "('know', 175)\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# Sort the dictionary by its values\n",
    "sorted_wdict = dict(sorted(wdict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# the top 100 most frequent word tokens\n",
    "nitem = 0 ; maxitems = 100\n",
    "for item in sorted_wdict.items():\n",
    "    nitem += 1\n",
    "    print(item)\n",
    "    if nitem == maxitems: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1196e3b-4c35-4798-9a82-5c47d7fc19ed",
   "metadata": {},
   "source": [
    "#### Those are the  top 100 most frequent word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56c26d45-b270-4888-adfa-5319055b6cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6399529802240354\n",
      "1.0473655096113954\n",
      "Adding up 2  make up the top 90% of word occurrences!\n"
     ]
    }
   ],
   "source": [
    "# number of words\n",
    "numberWords = len(wdict)\n",
    "\n",
    "occurrence = 0\n",
    "nitem = 0\n",
    "for item in sorted_wdict.items():\n",
    "    occurrence += item[1]\n",
    "    nitem += 1\n",
    "    print(occurrence / numberWords)\n",
    "    if occurrence / numberWords > 0.9: break\n",
    "print(f'Adding up {nitem}  make up the top 90% of word occurrences!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e67ff5-8fee-46c9-8e23-8c5364521738",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compute = 10000\n",
    "num_plot = 4000\n",
    "\n",
    "# Determine vocabulary to use for t-SNE/visualization.\n",
    "numbers = list(range(0, numberWords))\n",
    "#select data to use\n",
    "bert_char_indices_to_use = random.sample(numbers, num_compute)\n",
    "#select data to plot\n",
    "bert_voc_indices_to_plot = random.sample(bert_char_indices_to_use, num_plot)\n",
    "\n",
    "\n",
    "bert_voc_indices_to_use_tensor = torch.LongTensor(bert_voc_indices_to_use)\n",
    "bert_word_embs_to_use = wordembs(bert_voc_indices_to_use_tensor).detach().numpy()\n",
    "bert_words_to_plot = wdict[bert_voc_indices_to_plot]\n",
    "\n",
    "\n",
    "print(len(bert_voc_indices_to_plot))\n",
    "print(len(bert_voc_indices_to_use))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
